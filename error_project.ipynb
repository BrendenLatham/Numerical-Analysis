{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1\n",
        "#### Ashish Yonzon, Brenden Latham\n",
        "#### CPSMA-4413 Numerical Analysis\n",
        "#### Dr. Jacob"
      ],
      "metadata": {
        "id": "jXhgsaPWnZ4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "5ecHrWEq-tJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will create a couple functions. The first will be for finding true error and relative true error, while the second will be for approximate error and relative approximate error."
      ],
      "metadata": {
        "id": "idA4VYv60xrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "HyjPBrMm9K5-"
      },
      "outputs": [],
      "source": [
        "def errors(true_value,predicted_value):\n",
        "  true_error = true_value - predicted_value\n",
        "  relative_error = true_error / true_value\n",
        "  return(true_error,relative_error)\n",
        "  # print(f\"True error:{true_error} & Relative Error {relative_error}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apx_errors(current_value,previous_value):\n",
        "  apx_error = current_value - previous_value\n",
        "  apx_relative_error = apx_error / current_value\n",
        "  return(apx_error,apx_relative_error)\n",
        "  # print(f\"Approximate error:{apx_true_error} & Approximate Relative Error:{apx_relative_error}\")"
      ],
      "metadata": {
        "id": "sj8QOTMB_Mrq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the functions are as follows."
      ],
      "metadata": {
        "id": "IxAQSRman_Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errors(20,21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhBz1wOV-k4K",
        "outputId": "3f5b2bac-007a-4442-fe9d-cb616c029993"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1, -0.05)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "where 20 is the true value and 21 is the estimated value"
      ],
      "metadata": {
        "id": "2mIU7vSfO7vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apx_errors(21,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE9T4YGZ-qA7",
        "outputId": "86af84c1-f965-46fa-efdb-92b7c1f2a1c5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 0.047619047619047616)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where 21 is the current approximation and 20 is the previous approximation"
      ],
      "metadata": {
        "id": "XJC38-o8PETh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now explore the Taylor Series for e^x centered at 1"
      ],
      "metadata": {
        "id": "baqNdy9g01JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we define a function for the Taylor series."
      ],
      "metadata": {
        "id": "c43v0jW1dNMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def taylor_exp(x,a,degree):\n",
        "    return sum([(x-a)**n/math.factorial(n) for n in range(degree)])*math.exp(1)\n"
      ],
      "metadata": {
        "id": "3DS8MnJ2KW-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are centering at 1, we will set a=1. Also because e^x is equal to it's derivative, we will just need to multiply the output by e^1."
      ],
      "metadata": {
        "id": "QQuVfk73qcJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets see what this gives us when we have x=1.1 for e^x"
      ],
      "metadata": {
        "id": "KVJReoKrrcNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a list of degrees\n",
        "degrees = range(21)\n",
        "f = math.exp\n",
        "x = 1.1\n",
        "a = 1\n",
        "\n",
        "\n",
        "# Create a dictionary of values\n",
        "data = {'Degree': degrees,\n",
        "        'Actual Value': math.exp(x),\n",
        "        'Approximation': [taylor_exp(x,a, n) for n in degrees],\n",
        "\n",
        "        'True Error': [f(x) - taylor_exp(x,a, n) for n in degrees],\n",
        "        'Relative Error': [(f(x) - taylor_exp(x,a, n))/f(x) for n in degrees]}\n",
        "pd.options.display.float_format = '{:.15f}'.format\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set the Degree column as the index\n",
        "df.set_index('Degree', inplace=True)\n",
        "\n",
        "# Print the DataFrame\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "O27olqizik5T",
        "outputId": "212dc82a-16cf-41a0-8d03-254624940b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Actual Value     Approximation        True Error    Relative Error\n",
              "Degree                                                                        \n",
              "0      3.004166023946433 0.000000000000000 3.004166023946433 1.000000000000000\n",
              "1      3.004166023946433 2.718281828459045 0.285884195487388 0.095162581964041\n",
              "2      3.004166023946433 2.990110011304950 0.014056012641483 0.004678840160445\n",
              "3      3.004166023946433 3.003701420447245 0.000464603499188 0.000154653070265\n",
              "4      3.004166023946433 3.004154467418655 0.000011556527778 0.000003846833925\n",
              "5      3.004166023946433 3.004165793592940 0.000000230353493 0.000000076678017\n",
              "6      3.004166023946433 3.004166020116426 0.000000003830007 0.000000001274899\n",
              "7      3.004166023946433 3.004166023891817 0.000000000054616 0.000000000018180\n",
              "8      3.004166023946433 3.004166023945751 0.000000000000682 0.000000000000227\n",
              "9      3.004166023946433 3.004166023946425 0.000000000000008 0.000000000000003\n",
              "10     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "11     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "12     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "13     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "14     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "15     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "16     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "17     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "18     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "19     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000\n",
              "20     3.004166023946433 3.004166023946433 0.000000000000001 0.000000000000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea36fd64-5fda-4008-9446-0dd494d739ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Value</th>\n",
              "      <th>Approximation</th>\n",
              "      <th>True Error</th>\n",
              "      <th>Relative Error</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Degree</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000000</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>1.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>2.718281828459045</td>\n",
              "      <td>0.285884195487388</td>\n",
              "      <td>0.095162581964041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>2.990110011304950</td>\n",
              "      <td>0.014056012641483</td>\n",
              "      <td>0.004678840160445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.003701420447245</td>\n",
              "      <td>0.000464603499188</td>\n",
              "      <td>0.000154653070265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004154467418655</td>\n",
              "      <td>0.000011556527778</td>\n",
              "      <td>0.000003846833925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004165793592940</td>\n",
              "      <td>0.000000230353493</td>\n",
              "      <td>0.000000076678017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166020116426</td>\n",
              "      <td>0.000000003830007</td>\n",
              "      <td>0.000000001274899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023891817</td>\n",
              "      <td>0.000000000054616</td>\n",
              "      <td>0.000000000018180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023945751</td>\n",
              "      <td>0.000000000000682</td>\n",
              "      <td>0.000000000000227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946425</td>\n",
              "      <td>0.000000000000008</td>\n",
              "      <td>0.000000000000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>3.004166023946433</td>\n",
              "      <td>0.000000000000001</td>\n",
              "      <td>0.000000000000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea36fd64-5fda-4008-9446-0dd494d739ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea36fd64-5fda-4008-9446-0dd494d739ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea36fd64-5fda-4008-9446-0dd494d739ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "taylor_exp(10,1, 5),taylor_exp(10,1, 20),f(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTCMvLeRoiIL",
        "outputId": "920ebd85-714c-4c13-82c9-30653c4d5ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1210.6547693499472, 22003.206867097284, 22026.465794806718)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that when using up to the 20th degree, we get extremely close to the real value. Now let's visualize the difference between the real function and our Taylor Expansion when stopping at the 5th degree."
      ],
      "metadata": {
        "id": "tCYXXShWBS_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x):\n",
        "    return np.exp(x)\n",
        "\n",
        "\n",
        "x = np.linspace(0, 10, 1000)\n",
        "y = f(x)\n",
        "y_taylor = taylor_exp(x,1, 5)\n",
        "\n",
        "plt.plot(x, y, label='f(x)',color='blue')\n",
        "plt.plot(x, y_taylor, label='5th order Taylor series',color='red')\n",
        "plt.legend()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Fu-HEpI1jZJS",
        "outputId": "3629afc0-613f-453b-a27e-637b81246cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not very close is it. This is why it is important to use a sufficient number of degrees in your Taylor Expansions."
      ],
      "metadata": {
        "id": "LXy-ycNmBlIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next We will be looking at a common format for comparing approximations. We will examine the formula for euclidean distance from (0,0)"
      ],
      "metadata": {
        "id": "f9ma31AuCUNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def true_euclid(x,y):\n",
        "  return(math.sqrt((x**2)+(y**2)))\n",
        "\n",
        "def small_brain_euclid(x,y):\n",
        "  return(x+y)\n",
        "\n",
        "def big_brain_euclid(x,y):\n",
        "  return((.96*x)+(.4*y))"
      ],
      "metadata": {
        "id": "D9KXxTUklUDd"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_x_range = range(2,6,1)\n",
        "my_y_range = my_x_range\n",
        "for i in my_x_range:\n",
        "  for j in my_y_range:\n",
        "    print(\"true value:\",\n",
        "    true_euclid(i,j),\n",
        "    \" small brain value:\",\n",
        "    small_brain_euclid(i,j),\n",
        "    \" big brain value:\",\n",
        "    big_brain_euclid(i,j)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMXHWTdGIyRw",
        "outputId": "dbc8a45a-2654-486c-fad3-605d67d7f580"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true value: 2.8284271247461903  small brain value: 4  big brain value: 2.7199999999999998\n",
            "true value: 3.605551275463989  small brain value: 5  big brain value: 3.12\n",
            "true value: 4.47213595499958  small brain value: 6  big brain value: 3.52\n",
            "true value: 5.385164807134504  small brain value: 7  big brain value: 3.92\n",
            "true value: 3.605551275463989  small brain value: 5  big brain value: 3.6799999999999997\n",
            "true value: 4.242640687119285  small brain value: 6  big brain value: 4.08\n",
            "true value: 5.0  small brain value: 7  big brain value: 4.48\n",
            "true value: 5.830951894845301  small brain value: 8  big brain value: 4.88\n",
            "true value: 4.47213595499958  small brain value: 6  big brain value: 4.64\n",
            "true value: 5.0  small brain value: 7  big brain value: 5.04\n",
            "true value: 5.656854249492381  small brain value: 8  big brain value: 5.4399999999999995\n",
            "true value: 6.4031242374328485  small brain value: 9  big brain value: 5.84\n",
            "true value: 5.385164807134504  small brain value: 7  big brain value: 5.6\n",
            "true value: 5.830951894845301  small brain value: 8  big brain value: 6.0\n",
            "true value: 6.4031242374328485  small brain value: 9  big brain value: 6.4\n",
            "true value: 7.0710678118654755  small brain value: 10  big brain value: 6.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These approximations are not great, however I would assume that the more comples ones would match their braininess. Approximations of these two types can be used when wanting to avoid using a square root, however I am not sure what the other to types would be used for, as they just add more square roots and logs. I do agree with the braininess to an extent."
      ],
      "metadata": {
        "id": "h4T_s0BiMedz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have some great tools for approximating functions with Taylor Expansions. We have seen why it is necessary to use an N that is sufficient for the approximation. Overdoing it won't help either, because we have also seen that after a certain point the law of diminishing returns kicks in. We really have to choose N wisely. One way we can do this is by considering that while x increases, we might have to choose higher and higher values for N. Our graph shows a great representation of this. For N=5, once x reaches around 6, we can't really take the result of our Taylor Polynomial as a good approximation anymore."
      ],
      "metadata": {
        "id": "fz72HfnuQFXI"
      }
    }
  ]
}